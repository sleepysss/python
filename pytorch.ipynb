{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15984d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pytorch中模型训练步骤还是非常清晰的：\n",
    "\n",
    "数据载入及处理\n",
    "\n",
    "模型定义\n",
    "\n",
    "超参数设置（损失函数定义、优化器定义、训练轮数）\n",
    "\n",
    "训练模型\n",
    "\n",
    "读取一个batch的数据，并前向传播\n",
    "计算损失值\n",
    "反向传播计算梯度\n",
    "优化器优化模型\n",
    "循环执行上述过程直到规定轮数\n",
    "评估模型（非必须）\n",
    "\n",
    "测试模型\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b97c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "print(torch.backends.mps.is_available()) #m1 GPU available?\n",
    "print(torch.backends.mps.is_built()) #m1 GPU available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本運算單位為Tensor,為一個多維度的矩陣,可和numpy互轉\n",
    "\n",
    "#建立tensor\n",
    "w1=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "w2=torch.tensor([[2,2],[2,2],[2,2]])\n",
    "x=torch.empty(2,3) #創建空(未初始化)的tensor(2列3行)\n",
    "print(x.dtype) #資料型態\n",
    "print(x.size())\n",
    "y=torch.ones(2)\n",
    "z=torch.zeros(2,3,dtype=torch.int)\n",
    "a=torch.randn(2,3,5)\n",
    "\n",
    "# + - * / 皆為element-wise\n",
    "ans1=w1+w2 \n",
    "ans2=w1*w2 \n",
    "print(ans1,ans2,sep='\\n')\n",
    "\n",
    "#矩陣乘法\n",
    "x1=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "x2=torch.tensor([[1,2,3],[4,5,6]])\n",
    "ans=x1.mm(x2) #二為矩陣乘法\n",
    "print(ans)\n",
    "ans=torch.mm(x1,x2) #兩個相等\n",
    "print(ans)\n",
    "\n",
    "#三維帶batch矩陣乘法：\n",
    "\n",
    "#torch.bmm(a,b),tensor a 的size为(b,h,w),tensor b的size为(b,w,m) \n",
    "#也就是说两个tensor的第一维是相等的，然后第一个数组的第三维和第二个数组的第二维度要求一样，\n",
    "#对于剩下的则不做要求，输出维度 （b,h,m）\n",
    "\n",
    "#選取部分資料\n",
    "\n",
    "print(w1[0,:]) #取得第一個row的tensor\n",
    "print(w1[1:,:]) #取得第二個row以後的所有tensor\n",
    "print(x[:,0]) #取得第ㄧcolumn的tensor\n",
    "print(x[0,0]) #取得第一row,第一column的tensor\n",
    "print(x[0,0].item()) #取得第一row,第一column的item\n",
    "y1=y.numpy() #tensor to numpy\n",
    "z1=z.view(3,2) #reshape\n",
    "z2=z.reshape(3,2) #reshape和view功能基本一樣\n",
    "z3=z.reshape(3,-1) #-1代表這個維度的個數是剩下的所有元素個數\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d8662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#讀取資料\n",
    "#(1)圖片放在同一文件夾內,且另有一文件顯示標籤\n",
    "#(2)不同類別的圖片放在不同的文件夾內,且文件夾就是圖片的類別\n",
    "#(3)用torchvision來下載\n",
    "\n",
    "\n",
    "#(1)\n",
    "#需自定義一class來繼承torch.utils.data.dataset,並且要override 3個method\n",
    "#Dataset配Dataloader\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class TorchDataset(Dataset):\n",
    "    def __init__(self,filename,image_dir): \n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        \n",
    "        #filename:数据文件TXT：格式：imge_name.jpg label_id\n",
    "        #image_dir:图片路径：image_dir+imge_name.jpg构成图片的完整路径\n",
    "        \n",
    "        self.image_label_list=self.read_file(filename) #所有的name和label(type:tuple),用list存\n",
    "        self.image_dir=image_dir #不完整的地址\n",
    "        #self.len=len(self.image_label_list)\n",
    "    \n",
    "    def img_loader(self,image_path):\n",
    "        image = Image.open(image_path)\n",
    "        return image.convert('RGB')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read one data from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data pair (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        image_name,label=self.image_label_list[index] #tuple的讀取\n",
    "        print(self.image_label_list[index])\n",
    "        image_path=os.path.join(self.image_dir,image_name) #完整地址\n",
    "        print(image_path)\n",
    "        #下面三行是前處理\n",
    "        img = self.img_loader(image_path) \n",
    "        tranform = transforms.Compose([transforms.Resize((214, 214)), transforms.ToTensor()])\n",
    "        img = tranform(img)\n",
    "        label=np.array(label)\n",
    "        return img,label\n",
    "        \n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset (資料的筆數)\n",
    "        # --------------------------------------------\n",
    "        return len(self.image_label_list)\n",
    "\n",
    "    def read_file(self, filename): \n",
    "        image_label_list = []\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                # rstrip：用来去除结尾字符、空白符(包括\\n、\\r、\\t、' '，即：换行、回车、制表符、空格)\n",
    "                content = line.rstrip().split(',') #是','而不是' ',可能因為是csv檔的關係\n",
    "                name = content[0]\n",
    "                labels = []\n",
    "                for value in content[1:]:\n",
    "                    labels.append(int(value))\n",
    "                image_label_list.append((name, labels)) #用tuple的方式存到list裡\n",
    "        return image_label_list\n",
    "    \n",
    "train_filename='/Users/sleepy/Documents/python/data/dogcat.csv'\n",
    "image_dir='/Users/sleepy/Documents/python/data/cat&dog'\n",
    "batch_size=9\n",
    "epoch_num=2\n",
    "train_data = TorchDataset(filename=train_filename, image_dir=image_dir) #資料打包起來\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True) #如何取樣資料\n",
    "\n",
    "#DataLoader:用來產生批次訓練數據\n",
    "#DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,num_workers=0,collate_fn,pin_memory,drop_last=False)\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_image, batch_label in train_loader:\n",
    "        image=batch_image[0,:]\n",
    "        image=image.numpy()#image=np.array(image)\n",
    "        #image = image.transpose(1, 2, 0)  # 通道由[c,h,w]->[h,w,c]\n",
    "        #image_processing.cv_show_image(\"image\",image)\n",
    "        print(\"batch_image.shape:{},batch_label:{}\".format(batch_image.shape,batch_label))\n",
    "        # batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "#(2)\n",
    "#調用torchvision.datasets.ImageFolder來處理\n",
    "\n",
    "#ImageFolder(root,transform=None,target_transform=None,loader=default_loader)\n",
    "#  transform:對PIL image 進行轉換操作\n",
    "#  target_transform:對label進行轉換\n",
    "#  loader:default為讀取PIL image\n",
    "#\n",
    "#  Attributes:\n",
    "#  (1)classes: List of class names\n",
    "#  (2)class_to_idx: Dict with items(class_name,class_index)\n",
    "#  (3)imgs: List of (img path,class_index) tuples\n",
    "\n",
    "#DataLoader:用來產生批次訓練數據\n",
    "#DataLoader(dataset,batch_size=1,shuffle=False,sampler=None,num_workers=0,collate_fn,pin_memory,drop_last=False)\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((214, 214)), transforms.ToTensor()])\n",
    "trainset = ImageFolder('/Users/sleepy/Documents/python/data', transform=transform)\n",
    "print(trainset)\n",
    "print(trainset.class_to_idx)\n",
    "#trainset[0][0]:第一維度代表第幾張圖片第二維度為0代表圖片數據\n",
    "#trainset[0][1]:第二維度為1代表label(0,1,2,...)\n",
    "print(trainset[300][1])\n",
    "\n",
    "data_loader=torch.utils.data.DataLoader(trainset,batch_size=20,shuffle=True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#(3)\n",
    "data_train = datasets.MNIST(root = \"./data/\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "#root指定了数据集存放的路径，transform指定导入数据集时需要进行何种变换操作，train设置为True说明\n",
    "#导入的是训练集合，否则为测试集合。train如果为true，则从internet下载数据集并将其放在根目录中。如\n",
    "#果数据集已下载，则不会再次下载。\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0935751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建構model\n",
    "#使用torch.nn.Module，我们可以根据自己的需求改变传播过程，如RNN等\n",
    "#如果你需要快速构建或者不需要过多的过程，直接使用torch.nn.Sequential即可。\n",
    "\n",
    "#法1\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "#法2\n",
    "#繼承了torch.nn.Module,並需要override __init__和forward\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()  #python3可以直接用super().xxx代替super(class_name,self).xxx\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "net1 = Net(1, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d579547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #用來算gredient decent 第一個參數指定了什么参数应当被优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練\n",
    "\n",
    "def train( train_loader, val_loader, epochs, model, criterion, optimizer, Print_info=True ):\n",
    "    \n",
    "    train_loss_list = []\n",
    "    #val_loss_list = []\n",
    "    \n",
    "    model.train() #设置模型为训练模式,启用 batch normalization 和 dropout 。\n",
    "    \n",
    "    for epoch in range(epochs): #每一個epoch\n",
    "        loss = 0    \n",
    "        ###### Train ########\n",
    "        for X,y in train_loader: #X,y:批次中的圖片和标签数据。 \n",
    "            #也可for X,y in enumerate(train_loader, 0) 第二个参数表示迭代器的起始索引值，默认为0\n",
    "            #enumerate()\n",
    "            #>>> seq = ['one', 'two', 'three']\n",
    "            #>>> for i, element in enumerate(seq):\n",
    "            #...     print i, element\n",
    "            #...\n",
    "            #0 one\n",
    "            #1 two\n",
    "            #2 three\n",
    "            #也可for batch_idx, (images, labels) in enumerate(train_loader,0): \n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            \n",
    "            #前向传播\n",
    "            pred_y = model( X ) #当你调用一个类的实例对象时（即使用括号）(model是個object)，实际上是在调用该类的 __call__() 方法。\n",
    "            \n",
    "            计算损失函数\n",
    "            loss = criterion(pred_y, y) #当你调用一个类的实例对象时（即使用括号），实际上是在调用该类的 __call__() 方法。\n",
    "            #将梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            #反向传播\n",
    "            loss.backward()\n",
    "            #更新模型参数\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_list.append(loss.item()) #loss.item()可获取当前的损失值\n",
    "\n",
    "        '''\n",
    "        ###### Validation ######\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for X,y in val_dataloader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                pred_y = model( X )\n",
    "                loss = loss_fn(pred_y, y)\n",
    "                val_loss_list.append(loss.item())\n",
    "        '''\n",
    "                       \n",
    "    return train_loss_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
